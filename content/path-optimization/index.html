<!doctype html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
     <link rel="stylesheet" href="/libs/katex/katex.min.css">
     
    
    <link rel="stylesheet" href="/css/franklin.css">
    <link rel="stylesheet" href="/css/basic.css">
    <link rel="icon" href="/assets/favicon.png">
     <title>Some thoughts on global path optimization (Part 1/?)</title>  
</head>
<body>
    <header>
<div class="blog-name"><a href="/">Longest Path Search</a></div>
<nav>
  <ul>
    <li><a href="https://angeris.github.io">About</a></li>
    <li><a href="https://github.com/angeris">Code</a></li>
    <li><a href="/feed.xml">RSS feed</a></li>
    <li><a href="https://c.xkcd.com/random/comic/">Fun</a></li>
  </ul>
</nav>
</header>

    
    
    <div class="franklin-content">
        <h1>Some thoughts on global path optimization (Part 1/?)</h1>
        <p>Posted <strong>2017-10-17</strong></p>
    </div>
    
    <!-- Content appended here -->
    
<div class="franklin-content">
<p>I usually see path planning in some shape or form usually solved as a Bellman update, Dynamic Programming-style problem, where the given control is asymptotically stable and optimal; in general, this seems to work quite well, but when we have so much computational power available now-a-days, I do wonder if a global optimization approach is both feasible and maybe even better. There is some literature on this, but most of it is... I&#39;ll just say it&#39;s not really as interesting as I thought it would be, at first right.</p>
<p>That being said, if anyone has any papers that I should <em>definitely</em> read, please do send them over to my Twitter &#40;below&#41; or email, etc.; whatever floats your boat. I feel like I have a very limited view of the current state of the field, so I&#39;d always love to learn more&#33; That being said, a cursory search through Google Scholar isn&#39;t as productive as I would&#39;ve thought.</p>
<p>Anyways, let&#39;s get to something more interesting. I believe I&#39;ll be splitting this post up into some small set &#40;say, 3, though this may change&#41; posts explaining individual parts and more prickly details of the algorithm, but for now I&#39;ll just share the big idea and dive into the last part &#40;which I argue is the hardest case&#41;.</p>
<p>Essentially the problem will be broken down into three basic steps &#40;and a fourth &quot;looping&quot; step&#41;:</p>
<ol>
<li><p>Discretize the space and goals into a graph problem which is guaranteed to be &#40;a&#41; <em>damn fast to solve</em> and &#40;b&#41; to always give a feasible result &#40;minus a curvature constraint—that will come in later&#41;.</p>
</li>
<li><p>Make the resulting path through the graph into an ordered set of points \(x_i \in \mathbb{R}^2\) &#40;or \(\mathbb{R}^3\), depending on what problem needs to be solved&#41; through actual Euclidean space.</p>
</li>
<li><p>Perform continuous optimization starting at this resulting path in order to meet curvature constraints and add some &#39;finishing touches&#39; &#40;this will be formalized in a second, don&#39;t worry&#41;.</p>
</li>
<li><p>Do \((3)\) for moving objects, for a while, as \((1) \to (2)\) are solved again, simultaneously.</p>
</li>
</ol>
<p>In this post, I&#39;ll mostly focus on step \((3)\), which is actually all you need to truly optimize over a path &#40;along with some cute other heuristics&#41;, though steps \((1)\) and \((2)\) are also really just fast heuristics so we don&#39;t get stuck in crappy minima that would take us through the middle of an obstacle. I&#39;ll show how this can happen in non-obvious ways which is kinda fun for the first few times and mostly infuriating for the rest of the time &#40;which is why we end up going through \((1)\) and \((2)\) in the end&#33;&#41;.</p>
<h2 id="smooth_barriers"><a href="#smooth_barriers" class="header-anchor">Smooth barriers</a></h2>
<p>Perhaps the main idea of this step is that we can optimize over some function &#40;which isn&#39;t quite a hard-wall constraint&#41; and then slowly tune a parameter until it becomes a better and better approximation of a hard wall; for this example I&#39;ve chosen the &#40;reversed&#41; logistic function</p>
\[
\phi(x) = \frac{1}{1+e^{x}}
\]
<p>such that two things happen: one, that \(\phi(x) \to 0\) as \(x\to \infty\) and \(\phi(x) \to 1\) as \(x\to -\infty\), and, two, that \(\phi(Cx)\) approximates a hard wall as \(C\to \infty\). Below is \(\phi(Cx)\) plotted for a few different values of \(C\):</p>
<p>&lt;img src&#61;&quot;/images/path-optimization-1/phi_curvature.png&quot; class&#61;&quot;plot&quot;&gt; <em>Barrier functions for varying curvatures \(C\).</em></p>
<p>The idea is that the smooth problem should be easy to solve and we can get consistently better approximations by starting at the easy problem and solving a sequence of problems which, in the limit, give the desired path.</p>
<p>More generally speaking, let the obstacles be centered at some set of points \(\\{c\_j\\}\), each with some radius \(R\_j\), then a single constraint corresponds to the barrier of curvature \(C\) given by &#40;where the object is at position \(x\)&#41;</p>
\[
\phi\left(C\left(\frac{\lVert x - c_j \lVert_2^2}{R_j^2} - 1\right)\right)
\]
<p>which, if we assume that our path is characterized by an ordered set of points \(\\{x_i\\}\), gives our complete energy function to be</p>
\[
\mathcal{L}(x; c, R, C) = \sum_{ij}\phi\left(C\left(\frac{\lVert x_i - c_j \lVert_2^2}{R_j^2} - 1\right)\right)
\]
<p>which is really just a fancy way of writing &quot;each discretized point in my path should be outside of an obstacle.&quot; This is <em>close</em> to what we want, but it&#39;s not quite there yet: we aren&#39;t penalizing for being arbitrarily far away from other points—that is, if we just put all of our \(\\{x_i\\}\) at infinity, we now have zero penalty&#33;</p>
<p>Of course, that&#39;s a pretty stupid path that no drone can take &#40;especially if we&#39;re constrained to be in some particular region, which, in this case, we are&#41;, so we do the next straightforward thing: we also penalize any point being far away from its adjacent points. E.g. we add a penalty term of the form \(\eta\lVert x\_i - x\_{i+1}\lVert_2^2\) for \(\eta>0\). </p>
<p>In this case, our complete energy function then looks like</p>
\[
\mathcal{L}(x; c, R, C) = \sum_{i}\left[\sum_j\phi\left(C\left(\frac{\lVert x_i - c_j \lVert_2^2}{R_j^2} - 1\right)\right) + \eta \lVert x\_i - x\_{i+1}\lVert_2^2\right]
\]
<p>with a &#39;tunable&#39; parameter \(\eta\), and constraint wall &#39;hardness&#39; \(C\) which we send to infinity as we solve a sequence of problems. That is, let \(\\{C\_k\\}\) be a sequence such that \(C_k\to \infty\) then we solve the sequence of problems</p>
\[
x^{(k)} = \min\_x\mathcal{L}(x; c, R, C_k) 
\]
<p>and take the trajectory</p>
\[
x^* = \lim\_{k\to\infty} x^{(k)}
\]
<p>in the limit. Why do we do this? Because the derivative of \(\mathcal{L}\) vanishes as \(C\to\infty\) for the hard constraints. This can be seen in the picture above, by looking at the left side; as \(C\) becomes large, the function becomes essentially flat when \(x<0\) and \(x>0\). This is generally bad, since, if we were to optimize directly for some very large \(C\) which goes through the interior of an obstacle, we would be near a point where the derivative nearly vanishes even though we&#39;re inside of an obstacle&#33;</p>
<p>This is totally infeasible for our problem and we cannot sidestep this issue in an obvious way using general optimization tools. So we&#39;re forced to do the Next Best Thing™, which is to perform this cooling schedule idea while optimizing over the objective.<sup id="fnref:shortestpath"><a href="#fndef:shortestpath" class="fnref">[1]</a></sup></p>
<p>Anyways, optimizing this function somewhat successfully with some decent cooling schedule &#40;which is the subject of the next post&#41; yields a cute movie that looks like the following</p>
<p>&lt;video controls&gt;     &lt;source src&#61;&quot;/images/path-optimization-1/path_optimization.mp4&quot; type&#61;&quot;video/mp4&quot;&gt; &lt;/video&gt;</p>
<p>Don&#39;t be fooled, though: there&#39;s plenty of little experiments that didn&#39;t work out while making this. Robustness is a huge reason why optimizing just this objective would take way too long and, hence, why we require the heuristics mentioned above &#40;and which I&#39;ll soon discuss&#33;&#41;.</p>
<p>A general overview of the code &#40;with more details and implementation&#41; can be found in the <a href="https://github.com/StanfordAIR/optimization-sandbox">StanfordAIR Github repo</a>.</p>
<table class="fndef" id="fndef:shortestpath">
    <tr>
        <td class="fndef-backref"><a href="#fnref:shortestpath">[1]</a></td>
        <td class="fndef-content">As given before, we can create feasible trajectories which do not have this problem by discretization methods—this helps out quite a bit since, for complicated trajectories where a lot of the initial path intersects obstacles, most of the time is spent on either &#40;a&#41; making a good cooling schedule for \(C\) or &#40;b&#41; escaping the minima which include local obstacles. I&#39;ll discuss these methods in a later post.</td>
    </tr>
</table>

<div class="page-foot">
    Built with <a href="https://github.com/tlienart/Franklin.jl">Franklin.jl</a> and <a href="https://julialang.org">Julia</a>.
</div>
</div><!-- CONTENT ENDS HERE -->
    
        <script src="/libs/katex/katex.min.js"></script>
<script src="/libs/katex/auto-render.min.js"></script>
<script>renderMathInElement(document.body)</script>

    
    
  </body>
</html>
