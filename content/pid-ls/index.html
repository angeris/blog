<!doctype html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
     <link rel="stylesheet" href="/libs/katex/katex.min.css">
     
    
    <link rel="stylesheet" href="/css/franklin.css">
    <link rel="stylesheet" href="/css/basic.css">
    <link rel="icon" href="/assets/favicon.png">
     <title>PID as least squares</title>  
</head>
<body>
    <header>
<div class="blog-name"><a href="/">Longest Path Search</a></div>
<nav>
  <ul>
    <li><a href="https://angeris.github.io">About</a></li>
    <li><a href="https://github.com/angeris">Code</a></li>
    <li><a href="/feed.xml">RSS feed</a></li>
    <li><a href="https://c.xkcd.com/random/comic/">Fun</a></li>
  </ul>
</nav>
</header>

    
    
    <div class="franklin-content">
        <h1>PID as least squares</h1>
        <p>Posted <strong>2017-09-13</strong></p>
    </div>
    
    <!-- Content appended here -->
    
<div class="franklin-content">
<p>I want to say this is a folk theorem &#40;borrowing terminology from game theory&#41; in that everyone who does optimal control theory knows about this stuff, probably,<sup id="fnref:people"><a href="#fndef:people" class="fnref">[1]</a></sup> but I haven&#39;t really seen it stated explicitly anywhere. If anyone does indeed work on optimal control, I&#39;d love to know your thoughts&#33; &#40;even if you don&#39;t, I&#39;d still like to know your thoughts on it&#33;&#41;</p>
<p>For context, I&#39;m currently leading a team on path planning for fixed-wing UAVs &#40;I still don&#39;t really know who put me in charge of this stuff, or <em>why</em> for that matter–-overall, it seems pretty terrifying for them, but kinda fun for me&#41;, and I wondered why I hadn&#39;t actually seen least squares in many papers on fixed-wing control. I still haven&#39;t gotten an answer to the question, to be honest, but I did waste some potentially productive time showing that PID \(\subset\) LS. Some quick definitions: let \(u(t)\) be our control input and allow \(\varepsilon(t)\) to be the error of the function &#40;that is, \(\varepsilon(t) = x(t) - \hat x(t)\) where \(x(t)\) is the desired position and \(\hat x(t)\) is the current position&#41;, then a PID controller is defined as</p>
\[
u(t) = K_p \varepsilon(t) + K_i \int_0^t d\tau\,\varepsilon(\tau) + K_d\frac{\partial\varepsilon(t)}{\partial t}
\]
<p>where each of the \(K_{(\cdot)}\) variables are a gain or proportionality constant. Say \(K_p\) is the proportional constant &#40;i.e. how much of \(u\) is proportional to the current error&#41;, \(K_i\) is the integral proportionality constant &#40;i.e. how much of \(u\) is proportional to the integral of the error&#41;, and \(K_d\) is the derivative constant &#40;i.e. ditto&#41;. For a more thorough explanation for what each of these means intuitively, see the <a href="https://en.wikipedia.org/wiki/PID_controller">PID wikipedia page</a>.</p>
<p>Anyways, I&#39;ll likely make a separate &#40;more introductory&#41; post to least squares but, for now, I define an LS problem to be an optimization problem of the form, for arbitrary but given \(A, b, \lambda_j>0, C, d\)</p>
\[
\begin{aligned}
& \underset{u}{\text{minimize}}
& & \sum_j \lambda_j \lVert A_j u - b_j\lVert_2^2 \\
& \text{subject to}
& & Cu = d
\end{aligned}
\]
<p>where the \(\lVert \cdot \lVert_2^2\) norm is the usual \(\ell_2\)-norm &#40;i.e. \(\lVert x \lVert_2^2 = \sum_i x_i^2\)&#41;. It&#39;s notable that this problem has an analytical solution &#40;not that you&#39;d necessarily <em>want</em> the analytical solution for most big-enough scenarios&#41; and is extremely well-behaved for most optimization methods.<sup id="fnref:politifact"><a href="#fndef:politifact" class="fnref">[2]</a></sup> Now, consider the following objective function with trivial equality constraints &#40;e.g. \(0=0\), for convenience, by setting \(C = (0,0,…,0)^T,\, d = 0\)&#41; and \(K\) being some proportionality constant &#40;I&#39;ll make the connection to the original \(K_{(\cdot)}\) variables above, soon&#41;:</p>
\[
E(u, \varepsilon) = \lambda_p \left\lVert u - K\varepsilon (t)\right\lVert_2^2 + \lambda_i \left\lVert u - K\int d\tau\, \varepsilon(t)\right\lVert_2^2 + \lambda_d\left\lVert u - K \frac{\partial\varepsilon(t)}{\partial t}\right\lVert_2^2
\]
<p>Minimizing this function by setting its gradient to zero &#40;this is necessary and sufficient by differentiability, convexity, and coerciveness &#91;that is, \(E(u) \to \infty\), whenever \(\lVert u\lVert \to \infty\)&#93;&#41; gives the solution<sup id="fnref:generalization"><a href="#fndef:generalization" class="fnref">[3]</a></sup></p>
\[
\nabla E(u, \varepsilon) = \lambda_p \left(u - K\varepsilon (t)\right) + \lambda_i \left( u - K\int d\tau\, \varepsilon(t)\right) + \lambda_d\left(u - K \frac{\partial\varepsilon(t)}{\partial t}\right) = 0,
\]
<p>or, after rearranging</p>
\[
u = \frac{K}{\lambda_p + \lambda_i + \lambda_d}\left(\lambda_p \varepsilon(t) + \lambda_i\int d\tau\, \varepsilon(t) + \lambda_d \frac{\partial\varepsilon(t)}{\partial t}\right),
\]
<p>which allows the following correspondence between the original PID and the LS problem to be</p>
\[
\begin{aligned}
K &= K_p + K_i + K_d\\
\lambda_p &= \frac{K_p}{K}\\
\lambda_i &= \frac{K_i}{K}\\
\lambda_d &= \frac{K_d}{K}.
\end{aligned}
\]
<p>So, now we&#39;ve given the condition we wanted and we&#39;re done&#33;</p>
<p>Anyways, you may ask, why is this useful? I guess it kind of extends the framework to add constraints from your control surface, or secondary objectives. To be completely honest, though? I have no idea.</p>
<p><table class="fndef" id="fndef:people">
    <tr>
        <td class="fndef-backref"><a href="#fnref:people">[1]</a></td>
        <td class="fndef-content">I mostly know people who do hardware work, etc. on UAVs, so I don&#39;t really have a representative sample of control people.</td>
    </tr>
</table>
 <table class="fndef" id="fndef:politifact">
    <tr>
        <td class="fndef-backref"><a href="#fnref:politifact">[2]</a></td>
        <td class="fndef-content"><strong>PolitiFact</strong>: <em>Mostly true.</em> I mean the usual cases &#40;e.g. first-order methods, second-order methods, or conjugate gradient/quasi-newton methods&#41;. It&#39;s horribly behaved in conic program &#40;SOCP&#41; solvers.</td>
    </tr>
</table>
 <table class="fndef" id="fndef:generalization">
    <tr>
        <td class="fndef-backref"><a href="#fnref:generalization">[3]</a></td>
        <td class="fndef-content">There&#39;s an immediate generalization here: any control of the form \(\sum_i \gamma_i\left(u - C_i\right), \gamma_i>0\) can be immediately written as the minimizer to an energy function \(E(u) = \sum_i \eta_i\lVert u - \xi C_i\lVert^2_2\). We can actually go further and note there&#39;s yet another generalization to any control of the form \(\sum_i \left(S_iu - C_i\right)\), where each \(S_i\) is symmetric and &#40;strictly&#41; positive definite. This is true as each \(S_i\) has an inverse and a &#39;square root&#39; matrix &#40;e.g. let, \(S\) be some positive-definite matrix. We know \(SV =  V\Lambda\) for \(V^TV = VV^T = I\) and diagonal \(\Lambda > 0\), thus \(S^{1/2}=V\Lambda^{1/2}V^T\)&#41;, such that the energy function is written in terms of these. Though it&#39;s somewhat enlightening &#40;I guess&#41;, I leave the derivation as an exercise for the reader.</td>
    </tr>
</table>
</p>
<div class="page-foot">
    Built with <a href="https://github.com/tlienart/Franklin.jl">Franklin.jl</a> and <a href="https://julialang.org">Julia</a>.
</div>
</div><!-- CONTENT ENDS HERE -->
    
        <script src="/libs/katex/katex.min.js"></script>
<script src="/libs/katex/auto-render.min.js"></script>
<script>renderMathInElement(document.body)</script>

    
    
  </body>
</html>
